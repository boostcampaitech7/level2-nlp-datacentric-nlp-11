{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import evaluate\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 456\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "DEVICE\n",
    "MAX_SEQ_LENGTH = 36 \n",
    "BASE_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(BASE_DIR, '../data')\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, '../output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'klue/bert-base'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=7).to(DEVICE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "data = pd.read_csv(os.path.join('/data/ephemeral/home/level2-nlp-datacentric-nlp-11/data/merge_gj_sy_jh_ms_sn_clustering_clean_train_data_aug-google.csv'))\n",
    "dataset_train, dataset_valid = train_test_split(data, test_size=0.3, stratify=data['target'],random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=MAX_SEQ_LENGTH):\n",
    "        input_texts = data['clean_text'][(data[\"is_noise\"] == 1.0)&(data['clean_text']!='0')]\n",
    "        labels = data['target'][(data[\"is_noise\"] == 1.0)&(data['clean_text']!='0')]\n",
    "        self.inputs = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for text, label in zip(input_texts, labels):\n",
    "            tokenized_input = tokenizer(text, padding='max_length', truncation=True, max_length=max_length, return_tensors='pt')\n",
    "            self.inputs.append(tokenized_input)\n",
    "            self.labels.append(torch.tensor(label))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.inputs[idx]['input_ids'].squeeze(0),  \n",
    "            'attention_mask': self.inputs[idx]['attention_mask'].squeeze(0),\n",
    "            'labels': self.labels[idx].squeeze(0)\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#% matplotlib inline\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=7,output_hidden_states=True).to(DEVICE)\n",
    "model.config.problem_type = \"single_label_classification\" \n",
    "model.load_state_dict(torch.load('/data/ephemeral/home/level2-nlp-datacentric-nlp-11/output/11051351_merge_gj_sy_jh_new_ms_sn_clustering_clean_train_data_aug-google_model.bin'))\n",
    "data_all = BERTDataset(data, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "inputs = tokenizer(data.iloc[5]['text'],return_tensors='pt').to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "preds = []\n",
    "embedding = []\n",
    "for idx, sample in tqdm(data.iterrows()):\n",
    "    inputs = tokenizer(sample['text'], return_tensors=\"pt\").to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        embedding.append(model(inputs['input_ids'])[1][-1].squeeze()[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedding = pd.DataFrame(embedding)\n",
    "df_embedding['label'] = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_embedding.iloc[:,:-1].applymap(lambda x: x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = [int(x) for x in df_embedding['label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_text'] = data['clean_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 임베딩 데이터프레임 생성\n",
    "# df_embedding = pd.DataFrame(embedding)\n",
    "# df_embedding['label'] = data['target']\n",
    "# df_embedding['clean_text'] = data['clean_text']  # clean_text 추가\n",
    "\n",
    "# # 숫자 타입으로 변환 (필요한 경우)\n",
    "# df = df_embedding.copy()\n",
    "\n",
    "# 모든 열 이름을 문자열로 변환\n",
    "df.columns = df.columns.astype(str)\n",
    "\n",
    "# 'label'과 'clean_text'는 마지막 두 열이라고 가정\n",
    "feature_columns = df.columns[:-2]  # 임베딩 벡터 열\n",
    "df_features = df[feature_columns].applymap(lambda x: x.item() if hasattr(x, 'item') else x)\n",
    "\n",
    "# 'label'과 'clean_text' 추가\n",
    "df_features['label'] = df['label'].astype(int)\n",
    "df_features['clean_text'] = df['clean_text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# PCA 3D 실행\n",
    "pca_3d = PCA(n_components=3, random_state=42)\n",
    "X_pca_3d = pca_3d.fit_transform(df_features.iloc[:, :-2])\n",
    "\n",
    "# PCA 3D 결과 데이터프레임 생성\n",
    "df_pca_3d = pd.DataFrame(X_pca_3d, columns=['PC1', 'PC2', 'PC3'])\n",
    "df_pca_3d['Label'] = df_features['label'][(data[\"is_noise\"] == 1.0)&(data['clean_text']!='0')].astype(str)\n",
    "df_pca_3d['clean_text'] = df_features['clean_text'][(data[\"is_noise\"] == 1.0)&(data['clean_text']!='0')]\n",
    "\n",
    "# 인터랙티브 3D PCA 산점도 생성\n",
    "fig_pca_3d = px.scatter_3d(\n",
    "    df_pca_3d,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    z='PC3',\n",
    "    color='Label',\n",
    "    hover_data=['clean_text'],\n",
    "    title='Interactive 3D PCA Scatter Plot',\n",
    "    opacity=0.7,\n",
    "    width=1000,\n",
    "    height=800,\n",
    ")\n",
    "\n",
    "fig_pca_3d.update_layout(\n",
    "    legend_title_text='Label'\n",
    ")\n",
    "fig_pca_3d.update_traces(marker=dict(size=2))  # 여기서 3은 점의 크기, 필요한 크기로 조절\n",
    "\n",
    "fig_pca_3d.show()\n",
    "fig_pca_3d.write_html('interactive_3d_scatter.html')\n",
    "html_str = fig_pca_3d.to_html()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_str = fig_pca_3d.to_html()\n",
    "print(html_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# 2D t-SNE 실행\n",
    "n_components_2d = 2\n",
    "tsne_2d = TSNE(n_components=n_components_2d, random_state=42)\n",
    "X_embedded_2d = tsne_2d.fit_transform(df_features.iloc[:, :-2])  # 'label'과 'clean_text' 제외\n",
    "\n",
    "# 2D 임베딩 데이터프레임 생성\n",
    "df_embedded_2d = pd.DataFrame(X_embedded_2d, columns=['Component 1', 'Component 2'])\n",
    "df_embedded_2d['Label'] = df_features['label'][(data[\"is_noise\"] == 1.0)&(data['clean_text']!='0')].astype(str)  # 범주형 라벨을 문자열로 변환\n",
    "df_embedded_2d['clean_text'] = df_features['clean_text'][(data[\"is_noise\"] == 1.0)&(data['clean_text']!='0')]\n",
    "\n",
    "# 인터랙티브 2D 산점도 생성\n",
    "fig_2d = px.scatter(\n",
    "    df_embedded_2d,\n",
    "    x='Component 1',\n",
    "    y='Component 2',\n",
    "    color='Label',\n",
    "    hover_data=['clean_text'],\n",
    "    title='Interactive 2D t-SNE Scatter Plot',\n",
    "    opacity=0.7,\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig_2d.update_layout(\n",
    "    legend_title_text='Label'\n",
    ")\n",
    "\n",
    "fig_2d.show()\n",
    "fig_2d.write_html('interactive_2d_scatter.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# UMAP 실행\n",
    "umap_reducer = umap.UMAP(n_components=2, random_state=42)\n",
    "X_umap = umap_reducer.fit_transform(df_features.iloc[:, :-2])\n",
    "\n",
    "\n",
    "# UMAP 결과 데이터프레임 생성\n",
    "df_umap = pd.DataFrame(X_umap, columns=['UMAP1', 'UMAP2'])\n",
    "df_umap['Label'] = df_features['label'][(data[\"is_noise\"] == 1.0)&(data['clean_text']!='0')].astype(str)\n",
    "df_umap['clean_text'] = df_features['clean_text'][(data[\"is_noise\"] == 1.0)&(data['clean_text']!='0')]\n",
    "\n",
    "# 인터랙티브 2D UMAP 산점도 생성\n",
    "fig_umap = px.scatter(\n",
    "    df_umap,\n",
    "    x='UMAP1',\n",
    "    y='UMAP2',\n",
    "    color='Label',\n",
    "    hover_data=['clean_text'],\n",
    "    title='Interactive 2D UMAP Scatter Plot',\n",
    "    opacity=0.7,\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig_umap.update_layout(\n",
    "    legend_title_text='Label'\n",
    ")\n",
    "\n",
    "fig_umap.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, confusion_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "# 클러스터링 수행 (예: KMeans)\n",
    "n_clusters = 7\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(df_features.iloc[:, :-8])  # 'label'과 'clean_text' 제외\n",
    "\n",
    "# 실루엣 점수 계산\n",
    "silhouette_avg = silhouette_score(df_features.iloc[:, :-8], cluster_labels)\n",
    "silhouette_values = silhouette_samples(df_features.iloc[:, :-8], cluster_labels)\n",
    "\n",
    "# 데이터프레임에 클러스터 및 실루엣 점수 추가\n",
    "df_features['Cluster'] = cluster_labels\n",
    "df_features['Silhouette'] = silhouette_values\n",
    "\n",
    "print(f\"Average Silhouette Score: {silhouette_avg}\")\n",
    "\n",
    "# 아웃라이어 식별: 실루엣 점수가 0.25 미만인 데이터\n",
    "outliers = df_features[df_features['Silhouette'] < 0.25]\n",
    "print(f\"Number of outliers: {len(outliers)}\")\n",
    "\n",
    "# 실제 라벨 (예: df_features에 실제 라벨 컬럼이 있는 경우)\n",
    "true_labels = df_features['label']\n",
    "\n",
    "# 클러스터 라벨과 실제 라벨 간의 혼동 행렬 생성\n",
    "conf_matrix = confusion_matrix(true_labels, df_features['Cluster'])\n",
    "\n",
    "# 헝가리안 알고리즘을 사용하여 최적 매칭 찾기\n",
    "row_ind, col_ind = linear_sum_assignment(-conf_matrix)\n",
    "\n",
    "# 클러스터 라벨 재맵핑\n",
    "mapping = {old_label: new_label for old_label, new_label in zip(col_ind, row_ind)}\n",
    "df_features['Cluster'] = df_features['Cluster'].map(mapping)\n",
    "\n",
    "# 새로운 클러스터 라벨 확인\n",
    "print(\"Cluster label mapping:\")\n",
    "print(mapping)\n",
    "\n",
    "# 데이터프레임 확인\n",
    "print(df_features.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 클러스터 중심 계산\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "# 각 데이터 포인트와 클러스터 중심 간 거리 계산\n",
    "distances = []\n",
    "for idx, row in df_features.iterrows():\n",
    "    cluster = row['Cluster']\n",
    "    centroid = centroids[cluster]\n",
    "    distance = np.linalg.norm(row[:-8] - centroid)\n",
    "    distances.append(distance)\n",
    "\n",
    "df_features['Distance_to_Centroid'] = distances\n",
    "\n",
    "# 거리의 평균과 표준편차 계산\n",
    "mean_distance = df_features['Distance_to_Centroid'].mean()\n",
    "std_distance = df_features['Distance_to_Centroid'].std()\n",
    "\n",
    "# 아웃라이어 식별: 평균 + 2*표준편차 이상인 데이터\n",
    "distance_threshold = mean_distance + 1 * std_distance\n",
    "distance_outliers = df_features[df_features['Distance_to_Centroid'] > distance_threshold]\n",
    "print(f\"Number of distance-based outliers: {len(distance_outliers)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# 2D t-SNE 실행 (이미 클러스터링을 수행했다면 재실행할 필요 없음)\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "X_tsne = tsne.fit_transform(df_features.iloc[:, :-8])  # 'label', 'clean_text', 'Cluster' 제외\n",
    "\n",
    "df_tsne = pd.DataFrame(X_tsne, columns=['TSNE1', 'TSNE2'])\n",
    "df_tsne['Cluster'] = df_features['Cluster'].astype(str)\n",
    "df_tsne['Silhouette'] = df_features['Silhouette']\n",
    "df_tsne['clean_text'] = df_features['clean_text']\n",
    "\n",
    "# 아웃라이어는 실루엣 점수가 0.25 미만인 데이터\n",
    "df_tsne['Outlier'] = df_features['Silhouette'] < 0.25\n",
    "\n",
    "# 인터랙티브 2D t-SNE 산점도 생성\n",
    "fig_tsne = px.scatter(\n",
    "    df_tsne,\n",
    "    x='TSNE1',\n",
    "    y='TSNE2',\n",
    "    color='Cluster',\n",
    "    symbol='Outlier',\n",
    "    hover_data=['clean_text', 'Silhouette'],\n",
    "    title='2D t-SNE Scatter Plot with Outliers',\n",
    "    opacity=0.7,\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig_tsne.update_layout(\n",
    "    legend_title_text='Cluster'\n",
    ")\n",
    "\n",
    "fig_tsne.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거리 기반 아웃라이어 표시\n",
    "df_tsne['Distance_outlier'] = df_features['Distance_to_Centroid'] > distance_threshold\n",
    "\n",
    "fig_tsne_distance = px.scatter(\n",
    "    df_tsne,\n",
    "    x='TSNE1',\n",
    "    y='TSNE2',\n",
    "    color='Cluster',\n",
    "    symbol='Distance_outlier',\n",
    "    hover_data=['clean_text', 'Distance_outlier'],\n",
    "    title='2D t-SNE Scatter Plot with Distance-based Outliers',\n",
    "    opacity=0.7,\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig_tsne_distance.update_layout(\n",
    "    legend_title_text='Cluster'\n",
    ")\n",
    "\n",
    "fig_tsne_distance.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 아웃라이어 식별: 세 가지 방법 중 하나라도 해당하면 아웃라이어\n",
    "df_features['Final_Outlier'] = df_features['Silhouette'] < 0.2\n",
    "print(f\"Total number of final outliers: {len(df_features[df_features['Final_Outlier']])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아웃라이어 제거\n",
    "df_cleaned = df_features[df_features['Silhouette'] >= 0.20].copy()\n",
    "print(f\"Data shape after removing outliers: {df_cleaned.shape}\")\n",
    "# 아웃라이어 제거 후 CSV 파일로 출력\n",
    "output_path = '/data/ephemeral/home/level2-nlp-datacentric-nlp-11/data/clustering_delete_outlier_data.csv'  # 저장할 파일 이름 또는 경로\n",
    "selected_columns = ['clean_text', 'label', 'Cluster','Mapped_Cluster'] \n",
    "df_cleaned[selected_columns].to_csv(output_path, index=False)\n",
    "print(f\"Cleaned data saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아웃라이어를 새로운 클러스터로 할당 (예: 클러스터 7)\n",
    "df_features['Final_Cluster'] = df_features['Cluster']\n",
    "df_features.loc[df_features['Silhouette'] < 0.25, 'Final_Cluster'] = '7_Outlier'\n",
    "\n",
    "# 시각화 업데이트\n",
    "df_tsne['Final_Cluster'] = df_features['Final_Cluster'].astype(str)\n",
    "\n",
    "fig_final = px.scatter(\n",
    "    df_tsne,\n",
    "    x='TSNE1',\n",
    "    y='TSNE2',\n",
    "    color='Final_Cluster',\n",
    "    hover_data=['clean_text', 'Silhouette'],\n",
    "    title='2D t-SNE Scatter Plot with Final Clusters (Including Outliers)',\n",
    "    opacity=0.7,\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig_final.update_layout(\n",
    "    legend_title_text='Final Cluster'\n",
    ")\n",
    "\n",
    "fig_final.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# GMM 클러스터링 수행\n",
    "gmm = GaussianMixture(n_components=n_clusters, random_state=42)\n",
    "gmm_labels = gmm.fit_predict(df_features.iloc[:, :-9])\n",
    "\n",
    "# 각 데이터 포인트의 클러스터 할당 확률 가져오기\n",
    "probs = gmm.predict_proba(df_features.iloc[:, :-9])\n",
    "\n",
    "# 데이터프레임에 추가\n",
    "df_features['GMM_Cluster'] = gmm_labels\n",
    "df_features['GMM_Max_Prob'] = probs.max(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아웃라이어 데이터 가져오기 (예: Silhouette Score가 0.25 미만인 데이터)\n",
    "outliers = df_features[df_features['Silhouette'] < 0.25]\n",
    "\n",
    "# 아웃라이어의 인덱스 가져오기\n",
    "outlier_indices = outliers.index\n",
    "\n",
    "# 아웃라이어의 클러스터 할당 확률 가져오기\n",
    "outlier_probs = probs[outlier_indices]\n",
    "\n",
    "# 가장 높은 확률을 가진 클러스터 찾기\n",
    "reassigned_clusters = np.argmax(outlier_probs, axis=1)\n",
    "\n",
    "# 아웃라이어의 클러스터 재할당\n",
    "df_features.loc[outlier_indices, 'Reassigned_Cluster_GMM'] = reassigned_clusters\n",
    "\n",
    "# 재할당된 클러스터를 최종 클러스터로 업데이트\n",
    "df_features['Final_Cluster_GMM'] = df_features['Cluster']\n",
    "df_features.loc[outlier_indices, 'Final_Cluster_GMM'] = df_features.loc[outlier_indices, 'Reassigned_Cluster_GMM']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 재할당된 클러스터를 사용하여 시각화 업데이트\n",
    "df_tsne['Final_Cluster_GMM'] = df_features['Final_Cluster_GMM'].astype(str)\n",
    "df_tsne['GMM_Max_Prob'] = df_features['GMM_Max_Prob']\n",
    "fig_gmm = px.scatter(\n",
    "    df_tsne,\n",
    "    x='TSNE1',\n",
    "    y='TSNE2',\n",
    "    color='Final_Cluster_GMM',\n",
    "    hover_data=['clean_text', 'Silhouette', 'GMM_Max_Prob'],\n",
    "    title='2D t-SNE Scatter Plot with GMM Reassigned Outliers',\n",
    "    opacity=0.7,\n",
    "    width=800,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig_gmm.update_layout(\n",
    "    legend_title_text='Final Cluster (GMM)'\n",
    ")\n",
    "\n",
    "fig_gmm.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
